Notes from lectures.

##Packages
Beautiful Soup for interacting with webpages etc. package is already incorporated into Anaconda.


6.5 Write code using find() and string slicing (see section 6.10) to extract the number at the end of the line below. 
Convert the extracted value to a floating point number and print it out.

text = "X-DSPAM-Confidence:    0.8475";

pos = text.find(":")

string = text[pos+1:]

string.lstrip()

print float(string)

7.1 Write a program that prompts for a file name, then opens that file and reads through the file, and print the contents of the file in upper case. 
Use the file words.txt to produce the output below.
You can download the sample data at http://www.pythonlearn.com/code/words.txt

# Use words.txt as the file name
fname = raw_input("Enter file name: ")
fh = open(fname)

for line in fh:
	line = line.rstrip()
	print line.upper()

7.2 Write a program that prompts for a file name, then opens that file and reads through the file, looking for lines of the form:
X-DSPAM-Confidence:    0.8475
Count these lines and extract the floating point values from each of the lines and compute the average of those values and produce an output as shown below. 
Do not use the sum() function or a variable named sum in your solution.
You can download the sample data at http://www.pythonlearn.com/code/mbox-short.txt when you are testing below enter mbox-short.txt as the file name.

# Use the file name mbox-short.txt as the file name
fname = raw_input("Enter file name: ")
fh = open(fname)

c = 0
s = 0

for line in fh:
    if not line.startswith("X-DSPAM-Confidence:") : continue
    c = c + 1
    pos = line.find(":")
    string = line[pos+1:].lstrip()
    s = s + float(string)

avg = s / c
    
print "Average spam confidence: " + str(avg)


8.4 Open the file romeo.txt and read it line by line. For each line, split the line into a list of words using the split() method. The program should build a list of words. 
For each word on each line check to see if the word is already in the list and if not append it to the list. When the program completes, sort and print the resulting words in alphabetical order.
You can download the sample data at http://www.pythonlearn.com/code/romeo.txt

fname = raw_input("Enter file name: ")
fh = open(fname)
lst = list()
for line in fh:
	line = line.rstrip()
	line = line.split()
	
	for word in line:
		if word in lst: continue
		lst.append(word)
        
final = lst.sort()
print lst

8.5 Open the file mbox-short.txt and read it line by line. When you find a line that starts with 'From ' like the following line:
From stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008
You will parse the From line using split() and print out the second word in the line (i.e. the entire address of the person who sent the message). Then print out a count at the end.
Hint: make sure not to include the lines that start with 'From:'.

You can download the sample data at http://www.pythonlearn.com/code/mbox-short.txt

fname = raw_input("Enter file name: ")
if len(fname) < 1 : fname = "mbox-short.txt"

fh = open(fname)
count = 0
for line in fh:
    if not line.startswith("From ") : continue
    #if line.startswith("From"
    line = line.split()
    print line[1]
    count = count + 1
print "There were", count, "lines in the file with From as the first word"


9.4 Write a program to read through the mbox-short.txt and figure out who has the sent the greatest number of mail messages. The program looks for 'From ' lines and takes the second word of those lines as the person who sent the mail. 
The program creates a Python dictionary that maps the sender's mail address to a count of the number of times they appear in the file. 
After the dictionary is produced, the program reads through the dictionary using a maximum loop to find the most prolific committer.

name = raw_input("Enter file:")
if len(name) < 1 : name = "mbox-short.txt"
handle = open(name)

counts = dict()
senders = list()

for line in handle:
  if not line.startswith('From ') : continue
  words = line.split()
  sender = words[1]
  #print sender
  senders.append(sender)

for sender in senders:
  if sender not in counts:
    counts[sender] = 1
  else:
    counts[sender] = counts[sender] + 1
#print counts

max = 0


for key,value in counts.items():
  if value > max:
    max = value
    greatest = key,value

print greatest[0] + " " + str(greatest[1])


10.2 Write a program to read through the mbox-short.txt and figure out the distribution by hour of the day for each of the messages. 
You can pull the hour out from the 'From ' line by finding the time and then splitting the string a second time using a colon.
From stephen.marquard@uct.ac.za Sat Jan  5 09:14:16 2008
Once you have accumulated the counts for each hour, print out the counts, sorted by hour as shown below.

name = raw_input("Enter file:")
if len(name) < 1 : name = "mbox-short.txt"
handle = open(name)
counts = dict()
for line in handle:
	if not line.startswith("From ") : continue
        elements = line.split()
        time = elements[5]
        hour = time.split(':')
        hour = hour[0]
        counts[hour] = counts.get(hour, 0) + 1
lst = list()
for key, val in counts.items():
    	lst.append((key, val))
        
lst.sort(reverse=False)

for key, val in lst:
    print key, val

11.1 Read a file. Read through all the lines and extract all integers.

#code by Bram Raatjes
#version: 2017/03/05

import re

#files:
    #regex_sum_42.txt
    #regex_sum_354719.txt
filename = 'C:\\Users\\b.raatjes\\Dropbox\\Prive\\regex_sum_354719.txt'

fh = open(filename)

numlist = list()

for line in fh:
    line = line.rstrip()
    stuff = re.findall(('[0-9]+'), line)
    if len(stuff) == 0 : continue
    for num in stuff:
        numlist.append(num)
    
numlist = list(map(int, numlist)) 
    #this codeline above, in python 2.7, would look like:
    #'numlist = map(int, numlist)'

print("Sum: " + str(sum(numlist)))




13.2 Looping through webpages

#code by Bram Raatjes
#version: 2017/03/11
#Python2.7

testurl = 'http://python-data.dr-chuck.net/known_by_Fikret.html'
url = 'http://python-data.dr-chuck.net/known_by_Alexandria.html'

# Note - this code must run in Python 2.x and you must download
# http://www.pythonlearn.com/code/BeautifulSoup.py
# Into the same folder as this program

import urllib
from BeautifulSoup import *
c = 0
for x in range(0, 7):
	
	html = urllib.urlopen(url).read()
	soup = BeautifulSoup(html)
	c = c + 1
	# Retrieve all of the anchor tags
	lst = list()
	tags = soup('a')
	for tag in tags:
		lst.append(tag.get('href', None))
	url = lst[17]

	
print c
print(url)

14.1 Parsing XML from a webpage

Parsing XML

#code by Bram Raatjes
#version: 2017/03/13

testurl = 'http://python-data.dr-chuck.net/comments_42.xml'
realurl = 'http://python-data.dr-chuck.net/comments_354721.xml'

import urllib
import xml.etree.ElementTree as ET

data = urllib.urlopen(realurl).read()
#print 'Retrieved',len(data),'characters'

tree = ET.fromstring(data)

#print(type(data))

lst = list()
for comment in tree.findall('comments/comment'):
	count = int(comment.find('count').text)
	lst.append(count)
	#print(count)

print(sum(lst))
